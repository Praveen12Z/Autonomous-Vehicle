{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import fiftyone\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training dataset\n",
    "dataset_train = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"detections\"],\n",
    "    only_matching=True,\n",
    "    classes=[\"person\",\"bicycle\",\"car\",\"motorcycle\", \"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\"]\n",
    "    #max_samples=50,\n",
    ")\n",
    "\n",
    "# Export Training dataset\n",
    "\n",
    "dataset_train.export(\n",
    "    export_dir=\"/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset/train\",\n",
    "    dataset_type=fiftyone.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Validation dataset\n",
    "dataset_val = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    only_matching=True,\n",
    "    classes=[\"person\",\"bicycle\",\"car\",\"motorcycle\", \"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\"]\n",
    "    #max_samples=50,\n",
    ")\n",
    "\n",
    "# Export Validation dataset\n",
    "\n",
    "dataset_val.export(\n",
    "    export_dir=\"/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset/val\",\n",
    "    dataset_type=fiftyone.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring Data into YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions\n",
    "\n",
    "def read_json_file(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pathes\n",
    "input_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset'\n",
    "output_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo'\n",
    "\n",
    "# json anotation: dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])\n",
    "train_labels = read_json_file(os.path.join(input_path,'train/labels.json'))\n",
    "val_labels = read_json_file(os.path.join(input_path,'val/labels.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing images\n",
    "\n",
    "file_names = []\n",
    "\n",
    "def load_images_from_folder(folder,type = 'train'):\n",
    "  count = 0\n",
    "  for filename in os.listdir(folder):\n",
    "        source = os.path.join(folder,filename)\n",
    "        destination = f\"{output_path}/{type}_images/img{count}.jpg\"\n",
    "\n",
    "        try:\n",
    "            shutil.copy(source, destination)\n",
    "        # If source and destination are same\n",
    "        except shutil.SameFileError:\n",
    "            print(\"Source and destination represents the same file.\")\n",
    "\n",
    "        file_names.append(filename)\n",
    "        count += 1\n",
    "\n",
    "load_images_from_folder(os.path.join(input_path,'val/images'),type = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Labels format: one *.txt file per image\n",
    "\n",
    "- One row per object\n",
    "- Each row is class x_center y_center width height format.\n",
    "- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
    "- Class numbers are zero-indexed (start from 0).\n",
    "\n",
    "\n",
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset_val = CocoDetection(root = os.path.join(dataset_dir,'val/data'),annFile = os.path.join(dataset_dir,'val/labels.json'),transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 27,\n",
       "  'image_id': 4,\n",
       "  'category_id': 62,\n",
       "  'bbox': [408.03, 172.04000000000002, 19.38, 16.53],\n",
       "  'area': 320.3514,\n",
       "  'iscrowd': 0,\n",
       "  'supercategory': 'sports'},\n",
       " {'id': 28,\n",
       "  'image_id': 4,\n",
       "  'category_id': 49,\n",
       "  'bbox': [145.26, 100.67, 291.95, 457.35],\n",
       "  'area': 133523.3325,\n",
       "  'iscrowd': 0,\n",
       "  'supercategory': 'person'},\n",
       " {'id': 29,\n",
       "  'image_id': 4,\n",
       "  'category_id': 49,\n",
       "  'bbox': [163.73, 126.41999999999999, 265.69, 480.4],\n",
       "  'area': 127637.476,\n",
       "  'iscrowd': 0,\n",
       "  'supercategory': 'person'},\n",
       " {'id': 30,\n",
       "  'image_id': 4,\n",
       "  'category_id': 5,\n",
       "  'bbox': [368.64, 157.25, 57.45, 45.78],\n",
       "  'area': 2630.061,\n",
       "  'iscrowd': 0,\n",
       "  'supercategory': 'sports'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = dataset_val[3]\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 2414.4ms pre-process, 71.7ms inference, 1.1ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model(im)  # inference\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.91s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Set the root directory where you want to download the COCO dataset\n",
    "root_dir = r'/Users/daniil.yefimov/Desktop/Study/Uni Linz/Autonomus Vehicle/1. Perceptron Project/train2017'\n",
    "ann_dir = r'/Users/daniil.yefimov/Desktop/Study/Uni Linz/Autonomus Vehicle/1. Perceptron Project/annotations/instances_train2017.json'\n",
    "# Define transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and create the COCO dataset\n",
    "coco_dataset = CocoDetection(root=root_dir, annFile=ann_dir, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from COCO to Yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_ann(image_id):\n",
    "    img_ann = []\n",
    "    isFound = False\n",
    "    for ann in data['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            img_ann.append(ann)\n",
    "            isFound = True\n",
    "    if isFound:\n",
    "        return img_ann\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_img(filename):\n",
    "  for img in data['images']:\n",
    "    if img['file_name'] == filename:\n",
    "      return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'file_name': '000000000139.jpg',\n",
       " 'height': 426,\n",
       " 'width': 640,\n",
       " 'license': None,\n",
       " 'coco_url': None}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for filename in file_names:\n",
    "  # Extracting image \n",
    "  img = get_img(filename)\n",
    "  img_id = img['id']\n",
    "  img_w = img['width']\n",
    "  img_h = img['height']\n",
    "\n",
    "  # Get Annotations for this image\n",
    "  img_ann = get_img_ann(img_id)\n",
    "\n",
    "  if img_ann:\n",
    "    # Opening file for current image\n",
    "    file_object = open(f\"{output_path}/val_labels/img{count}.txt\", \"a\")\n",
    "\n",
    "    for ann in img_ann:\n",
    "      current_category = ann['category_id'] - 1 # As yolo format labels start from 0 \n",
    "      current_bbox = ann['bbox']\n",
    "      x = current_bbox[0]\n",
    "      y = current_bbox[1]\n",
    "      w = current_bbox[2]\n",
    "      h = current_bbox[3]\n",
    "      \n",
    "      # Finding midpoints\n",
    "      x_centre = (x + (x+w))/2\n",
    "      y_centre = (y + (y+h))/2\n",
    "      \n",
    "      # Normalization\n",
    "      x_centre = x_centre / img_w\n",
    "      y_centre = y_centre / img_h\n",
    "      w = w / img_w\n",
    "      h = h / img_h\n",
    "      \n",
    "      # Limiting upto fix number of decimal places\n",
    "      x_centre = format(x_centre, '.6f')\n",
    "      y_centre = format(y_centre, '.6f')\n",
    "      w = format(w, '.6f')\n",
    "      h = format(h, '.6f')\n",
    "          \n",
    "      # Writing current object \n",
    "      file_object.write(f\"{current_category} {x_centre} {y_centre} {w} {h}\\n\")\n",
    "\n",
    "    file_object.close()\n",
    "    count += 1  # This should be outside the if img_ann block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_rectangles(image_path, yolo_file_path, output_image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Read the YOLO format text file\n",
    "    with open(yolo_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # Parse YOLO format\n",
    "        values = line.split()\n",
    "        class_label = int(values[0])\n",
    "        x_center = float(values[1])\n",
    "        y_center = float(values[2])\n",
    "        width = float(values[3])\n",
    "        height = float(values[4])\n",
    "\n",
    "        # Convert YOLO format to OpenCV format\n",
    "        x = int((x_center - width / 2) * image.shape[1])\n",
    "        y = int((y_center - height / 2) * image.shape[0])\n",
    "        w = int(width * image.shape[1])\n",
    "        h = int(height * image.shape[0])\n",
    "\n",
    "        # Draw rectangle on the image\n",
    "        color = (0, 255, 0)  # Green color\n",
    "        thickness = 2\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "    cv2.imshow(\"Result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo/val_images/img1.jpg'\n",
    "yolo_file_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo/val_labels/img1.txt'\n",
    "output_image_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/output_image.jpg'\n",
    "\n",
    "draw_rectangles(image_path, yolo_file_path, output_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
