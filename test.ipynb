{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import fiftyone\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training dataset\n",
    "dataset_train = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"detections\"],\n",
    "    only_matching=True,\n",
    "    classes=[\"person\",\"bicycle\",\"car\",\"motorcycle\", \"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\"]\n",
    "    #max_samples=50,\n",
    ")\n",
    "\n",
    "# Export Training dataset\n",
    "\n",
    "dataset_train.export(\n",
    "    export_dir=\"/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset/train\",\n",
    "    dataset_type=fiftyone.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Validation dataset\n",
    "dataset_val = fiftyone.zoo.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    only_matching=True,\n",
    "    classes=[\"person\",\"bicycle\",\"car\",\"motorcycle\", \"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\"]\n",
    "    #max_samples=50,\n",
    ")\n",
    "\n",
    "# Export Validation dataset\n",
    "\n",
    "dataset_val.export(\n",
    "    export_dir=\"/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset/val\",\n",
    "    dataset_type=fiftyone.types.COCODetectionDataset,\n",
    "    label_field=\"ground_truth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring Data into YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils functions\n",
    "\n",
    "# Read Json file\n",
    "def read_json_file(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "# Copy files from one folder to another\n",
    "def copy_files_to_folder(source, destination):\n",
    "    count = 0\n",
    "    file_names = []\n",
    "    for filename in os.listdir(source):\n",
    "        source_file = os.path.join(source,filename)\n",
    "        destination_file = f\"{destination}/img{count}.jpg\"\n",
    "\n",
    "        try:\n",
    "            shutil.copy(source_file, destination_file)\n",
    "        except shutil.SameFileError:\n",
    "            print(\"Source and destination represents the same file.\")\n",
    "\n",
    "        file_names.append(filename)\n",
    "        count += 1\n",
    "\n",
    "    return file_names\n",
    "\n",
    "# Get image annotation\n",
    "def get_img_ann(image_id,labels_dict):\n",
    "    img_ann = []\n",
    "    isFound = False\n",
    "    for ann in labels_dict['annotations']:\n",
    "        if ann['image_id'] == image_id:\n",
    "            img_ann.append(ann)\n",
    "            isFound = True\n",
    "    if isFound:\n",
    "        return img_ann\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# Get image\n",
    "def get_img(filename,labels_dict):\n",
    "\tfor img in labels_dict['images']:\n",
    "\t\tif img['file_name'] == filename:\n",
    "\t\t\treturn img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pathes\n",
    "input_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset'\n",
    "output_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo'\n",
    "\n",
    "# Json anotation: dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])\n",
    "train_labels = read_json_file(os.path.join(input_path,'train/labels.json'))\n",
    "val_labels = read_json_file(os.path.join(input_path,'val/labels.json'))\n",
    "\n",
    "# Image files\n",
    "val_image_names = copy_files_to_folder(os.path.join(input_path,'val/images'),os.path.join(output_path,'val/images'))\n",
    "train_image_names = copy_files_to_folder(os.path.join(input_path,'train/images'),os.path.join(output_path,'train/images'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Labels format: one *.txt file per image\n",
    "\n",
    "- One row per object\n",
    "- Each row is class x_center y_center width height format.\n",
    "- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
    "- Class numbers are zero-indexed (start from 0).\n",
    "\n",
    "\n",
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset_val = CocoDetection(root = os.path.join(dataset_dir,'val/data'),annFile = os.path.join(dataset_dir,'val/labels.json'),transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons, 2 ties\n",
      "Speed: 2414.4ms pre-process, 71.7ms inference, 1.1ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
    "results = model(im)  # inference\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.91s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Set the root directory where you want to download the COCO dataset\n",
    "root_dir = r'/Users/daniil.yefimov/Desktop/Study/Uni Linz/Autonomus Vehicle/1. Perceptron Project/train2017'\n",
    "ann_dir = r'/Users/daniil.yefimov/Desktop/Study/Uni Linz/Autonomus Vehicle/1. Perceptron Project/annotations/instances_train2017.json'\n",
    "# Define transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and create the COCO dataset\n",
    "coco_dataset = CocoDetection(root=root_dir, annFile=ann_dir, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from COCO to Yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'file_name': '000000000139.jpg',\n",
       " 'height': 426,\n",
       " 'width': 640,\n",
       " 'license': None,\n",
       " 'coco_url': None}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for filename in file_names:\n",
    "  # Extracting image \n",
    "  img = get_img(filename)\n",
    "  img_id = img['id']\n",
    "  img_w = img['width']\n",
    "  img_h = img['height']\n",
    "\n",
    "  # Get Annotations for this image\n",
    "  img_ann = get_img_ann(img_id)\n",
    "\n",
    "  if img_ann:\n",
    "    # Opening file for current image\n",
    "    file_object = open(f\"{output_path}/val_labels/img{count}.txt\", \"a\")\n",
    "\n",
    "    for ann in img_ann:\n",
    "      current_category = ann['category_id'] - 1 # As yolo format labels start from 0 \n",
    "      current_bbox = ann['bbox']\n",
    "      x = current_bbox[0]\n",
    "      y = current_bbox[1]\n",
    "      w = current_bbox[2]\n",
    "      h = current_bbox[3]\n",
    "      \n",
    "      # Finding midpoints\n",
    "      x_centre = (x + (x+w))/2\n",
    "      y_centre = (y + (y+h))/2\n",
    "      \n",
    "      # Normalization\n",
    "      x_centre = x_centre / img_w\n",
    "      y_centre = y_centre / img_h\n",
    "      w = w / img_w\n",
    "      h = h / img_h\n",
    "      \n",
    "      # Limiting upto fix number of decimal places\n",
    "      x_centre = format(x_centre, '.6f')\n",
    "      y_centre = format(y_centre, '.6f')\n",
    "      w = format(w, '.6f')\n",
    "      h = format(h, '.6f')\n",
    "          \n",
    "      # Writing current object \n",
    "      file_object.write(f\"{current_category} {x_centre} {y_centre} {w} {h}\\n\")\n",
    "\n",
    "    file_object.close()\n",
    "    count += 1  # This should be outside the if img_ann block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def draw_rectangles(image_path, yolo_file_path, output_image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Read the YOLO format text file\n",
    "    with open(yolo_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # Parse YOLO format\n",
    "        values = line.split()\n",
    "        class_label = int(values[0])\n",
    "        x_center = float(values[1])\n",
    "        y_center = float(values[2])\n",
    "        width = float(values[3])\n",
    "        height = float(values[4])\n",
    "\n",
    "        # Convert YOLO format to OpenCV format\n",
    "        x = int((x_center - width / 2) * image.shape[1])\n",
    "        y = int((y_center - height / 2) * image.shape[0])\n",
    "        w = int(width * image.shape[1])\n",
    "        h = int(height * image.shape[0])\n",
    "\n",
    "        # Draw rectangle on the image\n",
    "        color = (0, 255, 0)  # Green color\n",
    "        thickness = 2\n",
    "        image = cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "    cv2.imshow(\"Result\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo/val_images/img1.jpg'\n",
    "yolo_file_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/dataset_yolo/val_labels/img1.txt'\n",
    "output_image_path = '/Users/daniil.yefimov/Desktop/GitHub/Autonomous-Vehicle/output_image.jpg'\n",
    "\n",
    "draw_rectangles(image_path, yolo_file_path, output_image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
